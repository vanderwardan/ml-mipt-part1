{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\vande\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\vande\\anaconda3\\lib\\site-packages (from gensim)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\vande\\anaconda3\\lib\\site-packages (from gensim)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\vande\\anaconda3\\lib\\site-packages (from gensim)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in c:\\users\\vande\\anaconda3\\lib\\site-packages (from gensim)\n",
      "Requirement already satisfied: boto>=2.32 in c:\\users\\vande\\anaconda3\\lib\\site-packages (from smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: boto3 in c:\\users\\vande\\anaconda3\\lib\\site-packages (from smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: requests in c:\\users\\vande\\anaconda3\\lib\\site-packages (from smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: bz2file in c:\\users\\vande\\anaconda3\\lib\\site-packages (from smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\vande\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: botocore<1.10.0,>=1.9.22 in c:\\users\\vande\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in c:\\users\\vande\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\vande\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\vande\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\vande\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vande\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: docutils>=0.10 in c:\\users\\vande\\anaconda3\\lib\\site-packages (from botocore<1.10.0,>=1.9.22->boto3->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: python-dateutil<2.7.0,>=2.1 in c:\\users\\vande\\anaconda3\\lib\\site-packages (from botocore<1.10.0,>=1.9.22->boto3->smart-open>=1.2.1->gensim)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip.main([\"install\", \"gensim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vande\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import gensim\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/eyaler/word2vec-slim/blob/master/GoogleNews-vectors-negative300-SLIM.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"labeledTrainData.tsv\", sep=\"\\t\")\n",
    "test = pd.read_csv(\"testData.tsv\", sep=\"\\t\")\n",
    "\n",
    "labels = train.sentiment\n",
    "\n",
    "train.drop([\"id\", \"sentiment\"], axis=1, inplace=True)\n",
    "test.drop([\"id\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    regex = \"[^a-zA-Z0-9 ]\"\n",
    "    cleaned_text = re.sub(regex, \"\", text).lower()\n",
    "    \n",
    "    \"\"\"You may add stemming here\"\"\"\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "assert clean_text(\"ASDASDAsdads.,,   asd,.ads012\") == 'asdasdasdads   asdads012'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = pd.concat([train, test], axis=0)\n",
    "\n",
    "all[\"review\"] = all[\"review\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading projection weights from GoogleNews-vectors-negative300-SLIM.bin.gz\n",
      "loaded (299567, 300) matrix from GoogleNews-vectors-negative300-SLIM.bin.gz\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300-SLIM.bin.gz\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def get_vector(words):\n",
    "    words = list(filter(lambda word: word in model.vocab.keys(), words.split()))\n",
    "    \n",
    "    if not words:\n",
    "        return np.zeros(shape=vectors[0].shape[0])\n",
    "    \n",
    "    return np.mean([model[word] for word in words], axis=0)\n",
    "\n",
    "review_vectors = all.review.apply(get_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "_ = tfidf.fit_transform(all.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = list(tfidf.idf_)\n",
    "vocab = tfidf.vocabulary_\n",
    "\n",
    "idfs = {key:idfs[value] for key, value in vocab.items()}\n",
    "\n",
    "def get_vector(words):\n",
    "    words = list(filter(lambda word: word in model.vocab.keys() and word in tfidf.vocabulary_.keys(), words.split()))\n",
    "    \n",
    "    if not words:\n",
    "        return np.zeros(shape=vectors[0].shape[0])\n",
    "    \n",
    "    tf = [vocab[word] / len(words) for word in words]\n",
    "    weights = np.array([idfs[word] for word in words])\n",
    "    word_vecs = [model[word] * tf[i] for i, word in enumerate(words)]\n",
    "    \n",
    "    return np.multiply(word_vecs, weights.reshape(-1, 1)).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "review_vectors = all.review.apply(get_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "del idfs\n",
    "del vocab\n",
    "del tfidf\n",
    "del all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vs = np.vstack(review_vectors.values)\n",
    "del review_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9102913850487356\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lr = LogisticRegression(C=1e-4)\n",
    "print(cross_val_score(lr, w2vs[:train.shape[0]], labels, scoring=\"roc_auc\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=1e-4)\n",
    "lr.fit(w2vs[:train.shape[0]], labels)\n",
    "preds = lr.predict_proba(w2vs[train.shape[0]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(preds):\n",
    "    submission = pd.read_csv(\"sampleSubmission.csv\")\n",
    "    submission.sentiment = preds\n",
    "    submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submit(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
